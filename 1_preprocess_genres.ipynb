{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T04:20:52.384918800Z",
     "start_time": "2024-06-04T04:20:52.301394800Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "722ce30e7d00b6ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T10:59:05.509292900Z",
     "start_time": "2024-06-03T10:59:00.489639400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Meiji/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/Meiji/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/Meiji/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb9e8b1-ea66-46a7-8362-f6b90731486e",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1349796420625b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T11:01:47.028396400Z",
     "start_time": "2024-06-03T11:01:46.121693Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "wiki_movie_plots = pd.read_csv('wiki_movie_plots_deduped.csv')\n",
    "wiki_movie_plots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bd5ba7-c3f0-4e59-af82-b081c1e34148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_genres = list(wiki_movie_plots['Genre'].unique())\n",
    "print('>> Number of raw genres:', len(all_genres))\n",
    "print('>> Number of raw rows:', wiki_movie_plots.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8a3880-7fe8-46de-81d0-471761427574",
   "metadata": {},
   "source": [
    "# Preprocessing genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08970528-71a7-4d2f-9b7f-e484d0363c95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ALLOWED_GENRES = {'action', 'adventure', 'animated', 'biographical', 'comedy', 'crime',\n",
    "                  'drama', 'fantasy', 'history', 'horror', 'music', 'mystery',\n",
    "                  'romance', 'scifi', 'sport', 'thriller', 'war', 'western', 'documentary'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81442161-812f-4b93-b800-6b2ac2929c8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_genres(genre_string):\n",
    "    \n",
    "    \"\"\"\n",
    "    Processes a single genre string by first splitting it on non-hyphen non-alphanumeric characters, applying\n",
    "    predefined replacements to standardize genre names, splitting again by hyphens, and then filtering genres\n",
    "    against a predefined list. Any genre not in the allowed list is classified as \"other\".\n",
    "\n",
    "    Parameters:\n",
    "    - genre_string (str): A string containing multiple genre descriptions which may include separators like commas or slashes.\n",
    "\n",
    "    Returns:\n",
    "    - str: A comma-separated sorted list of unique genre names standardized according to a predefined list of allowed genres.\n",
    "            Unrecognized genres are labeled as \"other\".\n",
    "\n",
    "    This function ensures that genre names are consistent and categorized, facilitating easier analysis and usage in\n",
    "    data processing tasks.\n",
    "\n",
    "    Example:\n",
    "    genre_string = \"sci-fi, romantic-comedy, epic-war, unknown style, crime-drama\"\n",
    "    result = preprocess_genres(genre_string)\n",
    "    print(result)  # Output might include 'scifi', 'romance', 'war', 'other', etc., based on the input and settings.\n",
    "    \"\"\"\n",
    "    \n",
    "    replacements = {\n",
    "        'biodrama': 'biographical-drama',\n",
    "        'docudrama': 'documentary-drama',\n",
    "        'melodrama': 'drama',\n",
    "        'sci-fi': 'scifi',\n",
    "        'science-fiction': 'scifi',\n",
    "        'science fiction': 'scifi',\n",
    "        'rom com': 'romance-comedy',\n",
    "        'romcom': 'romance-comedy',\n",
    "        'rom-com': 'romance-comedy',\n",
    "        'romantic comedy': 'romance-comedy',\n",
    "        'romantic': 'romance',\n",
    "        'rom-comedy': 'romance-comedy',\n",
    "        'bio': 'biographical',\n",
    "        'biographic': 'biographical',\n",
    "        'biography': 'biographical',\n",
    "        'anime': 'animated',\n",
    "        'animation': 'animated'\n",
    "    }\n",
    "\n",
    "    # Convert to lowercase and perform initial splitting\n",
    "    genres = re.split(r'[^a-zA-Z0-9\\-]+', genre_string.lower())\n",
    "\n",
    "    processed_genres = set()\n",
    "    for genre in genres:\n",
    "        # Apply replacements\n",
    "        for old, new in replacements.items():\n",
    "            genre = re.sub(r'\\b{}\\b'.format(re.escape(old)), new, genre)\n",
    "        \n",
    "        # Split by hyphens and validate genres\n",
    "        subgenres = genre.split('-')\n",
    "        for subgenre in subgenres:\n",
    "            clean_subgenre = subgenre.strip()\n",
    "            if clean_subgenre in ALLOWED_GENRES:\n",
    "                processed_genres.add(clean_subgenre)\n",
    "            elif clean_subgenre:\n",
    "                processed_genres.add('other')\n",
    "\n",
    "    return ','.join(sorted(processed_genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1989a912-8482-44f0-98bd-b47081445128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the preprocessing\n",
    "genres_processed = pd.Series(wiki_movie_plots['Genre']).apply(preprocess_genres)\n",
    "print(genres_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7bb21d-0279-47d6-a442-d0f6bafc1f0c",
   "metadata": {},
   "source": [
    "# Restructure Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be5543-53dc-45cc-9967-e0c07ef112e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a 0-1 binary column for each genre in the list, and append back to the dataframe\n",
    "wiki_movie_plots_processed = pd.concat([wiki_movie_plots, genres_processed.str.get_dummies(sep=',')], axis=1)\n",
    "wiki_movie_plots_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8efcb0-9ff7-41c7-9a70-0b1345372adc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter rows with at least 1 specific (non-other) genre, and remove the other column.\n",
    "# Filtering logic: not(other==1 and row_sum(all genre columns)==1)\n",
    "\n",
    "# rows_with_other_genre_only = genres[(genres['other'] == 1) & (genres.sum(axis=1)==1)]\n",
    "wiki_movie_plots_processed = wiki_movie_plots_processed[~((wiki_movie_plots_processed['other'] == 1) & (wiki_movie_plots_processed.iloc[:,8:].sum(axis=1)==1))].drop('other', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6338db9-11b4-4329-8541-8c5df39b9666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('>> Number of raw rows:', wiki_movie_plots.shape[0])\n",
    "print('>> Number of processed rows:', wiki_movie_plots_processed.shape[0])\n",
    "print('>> Processed rows %:', wiki_movie_plots_processed.shape[0]/wiki_movie_plots.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed2aabf-77c5-41c3-97d8-5e467929fd0c",
   "metadata": {},
   "source": [
    "## Save as 'data_processed_genres.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8922243-a321-4b08-b48e-cb4ce5d074db",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movie_plots_processed.to_csv('data_processed_genres.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60654b68-b4c3-4e1d-9128-be20915db20a",
   "metadata": {},
   "source": [
    "# Check multi-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6cb98d3-8b83-498e-b1bd-332aa68b412d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    20602\n",
       "2     4694\n",
       "3      536\n",
       "4      111\n",
       "0       31\n",
       "5       17\n",
       "6        1\n",
       "7        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of n-label rows\n",
    "label_count = wiki_movie_plots_processed.iloc[:,8:].sum(axis=1).value_counts()\n",
    "label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1492d0-8090-4fb8-9c3a-36470dbf9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('>> % multi-label:', 1-((label_count[1]+label_count[0])/sum(label_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f89e0e-a756-4aa3-bdde-9f1f8c7ac5c0",
   "metadata": {},
   "source": [
    "# Preprocessing plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbfcd8e-6e30-45b3-8967-9edaa72c657f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_plot(plot):\n",
    "    if isinstance(plot, float):\n",
    "        # Handle NaN or non-string plot descriptions\n",
    "        return \"\"\n",
    "    \n",
    "    # Tokenize the plot\n",
    "    tokens = word_tokenize(plot)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    \n",
    "    # Remove punctuation\n",
    "    tokens = [word for word in tokens if word.isalnum()]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatize the tokens\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    processed_plot = ' '.join(tokens)\n",
    "    \n",
    "    return processed_plot\n",
    "\n",
    "movie_data = wiki_movie_plots_processed\n",
    "\n",
    "# Apply preprocessing to the 'Plot' column\n",
    "movie_data['Processed_Plot'] = movie_data['Plot'].apply(preprocess_plot)\n",
    "\n",
    "# Display the first few rows of the dataset to confirm preprocessing\n",
    "print(movie_data[['Plot', 'Processed_Plot']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0482ca7f-29b3-4a38-971f-f5d63804e9b8",
   "metadata": {},
   "source": [
    "## Save as 'preprocessed_movie_plots.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd13f143-138b-42db-b576-5b5812816171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the preprocessed data to a new file\n",
    "output_file_path = 'preprocessed_movie_plots.xlsx'\n",
    "movie_data.to_excel(output_file_path, index=False)\n",
    "print(f\"Preprocessed data saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2b39a0-9187-411d-b5c3-b03bf26b17d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
